{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### porto-seguro Baseline 모델\n",
    "- 탐색적 데이터 분석 과정을 통해 확인결과 변수들은 모두 익명화되어있고 값들은 숫자로 치환되어있음.\n",
    "- 범주형 변수도 이미 숫자로 치환되어있어, 데이터 전처리를 수행할 필요가 없을 만큼 데이터가 깔끔하고 깨끗함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 2-1. 훈련 데이터, 테스트 데이터 읽어오기.\n",
    "data_path = 'D:/dataset/porto-seguro-safe-driver-prediction/'\n",
    "trn = pd.read_csv(data_path + 'train.csv')\n",
    "tst = pd.read_csv(data_path + 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실제 변수 이름을 알수 없어 피쳐 엔지니이렁시 초기에 방향성 찾기가 어려울 수 있음.\n",
    "##### => 3가지 기초 피쳐 엔지니어링 수행(파생변수 생성)\n",
    "- (1) 결측값의 갯수를 나타내는 missing 변수 \n",
    "- (2) 이진 변수들의 총합\n",
    "- (3) Target Encoding 파생 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1.0\n",
      "1         2.0\n",
      "2         3.0\n",
      "3         0.0\n",
      "4         2.0\n",
      "5         1.0\n",
      "6         1.0\n",
      "7         0.0\n",
      "8         1.0\n",
      "9         0.0\n",
      "10        2.0\n",
      "11        2.0\n",
      "12        2.0\n",
      "13        0.0\n",
      "14        2.0\n",
      "15        2.0\n",
      "16        2.0\n",
      "17        0.0\n",
      "18        3.0\n",
      "19        2.0\n",
      "20        2.0\n",
      "21        2.0\n",
      "22        0.0\n",
      "23        2.0\n",
      "24        1.0\n",
      "25        2.0\n",
      "26        1.0\n",
      "27        1.0\n",
      "28        2.0\n",
      "29        1.0\n",
      "         ... \n",
      "595182    1.0\n",
      "595183    2.0\n",
      "595184    2.0\n",
      "595185    0.0\n",
      "595186    0.0\n",
      "595187    1.0\n",
      "595188    3.0\n",
      "595189    0.0\n",
      "595190    2.0\n",
      "595191    2.0\n",
      "595192    3.0\n",
      "595193    2.0\n",
      "595194    1.0\n",
      "595195    0.0\n",
      "595196    2.0\n",
      "595197    3.0\n",
      "595198    0.0\n",
      "595199    1.0\n",
      "595200    2.0\n",
      "595201    0.0\n",
      "595202    0.0\n",
      "595203    0.0\n",
      "595204    2.0\n",
      "595205    0.0\n",
      "595206    2.0\n",
      "595207    1.0\n",
      "595208    3.0\n",
      "595209    2.0\n",
      "595210    2.0\n",
      "595211    3.0\n",
      "Name: missing, Length: 595212, dtype: float64\n",
      "0         2.0\n",
      "1         1.0\n",
      "2         2.0\n",
      "3         3.0\n",
      "4         2.0\n",
      "5         2.0\n",
      "6         2.0\n",
      "7         2.0\n",
      "8         1.0\n",
      "9         3.0\n",
      "10        2.0\n",
      "11        2.0\n",
      "12        1.0\n",
      "13        2.0\n",
      "14        1.0\n",
      "15        2.0\n",
      "16        2.0\n",
      "17        2.0\n",
      "18        2.0\n",
      "19        3.0\n",
      "20        0.0\n",
      "21        2.0\n",
      "22        0.0\n",
      "23        2.0\n",
      "24        3.0\n",
      "25        2.0\n",
      "26        0.0\n",
      "27        2.0\n",
      "28        1.0\n",
      "29        2.0\n",
      "         ... \n",
      "892786    1.0\n",
      "892787    0.0\n",
      "892788    2.0\n",
      "892789    2.0\n",
      "892790    1.0\n",
      "892791    3.0\n",
      "892792    1.0\n",
      "892793    1.0\n",
      "892794    1.0\n",
      "892795    1.0\n",
      "892796    0.0\n",
      "892797    3.0\n",
      "892798    0.0\n",
      "892799    2.0\n",
      "892800    3.0\n",
      "892801    1.0\n",
      "892802    1.0\n",
      "892803    2.0\n",
      "892804    0.0\n",
      "892805    0.0\n",
      "892806    2.0\n",
      "892807    1.0\n",
      "892808    2.0\n",
      "892809    1.0\n",
      "892810    1.0\n",
      "892811    1.0\n",
      "892812    1.0\n",
      "892813    2.0\n",
      "892814    1.0\n",
      "892815    0.0\n",
      "Name: missing, Length: 892816, dtype: float64\n",
      "0         5\n",
      "1         5\n",
      "2         5\n",
      "3         2\n",
      "4         4\n",
      "5         6\n",
      "6         4\n",
      "7         5\n",
      "8         4\n",
      "9         4\n",
      "10        6\n",
      "11        4\n",
      "12        4\n",
      "13        4\n",
      "14        3\n",
      "15        5\n",
      "16        3\n",
      "17        4\n",
      "18        3\n",
      "19        5\n",
      "20        4\n",
      "21        3\n",
      "22        3\n",
      "23        4\n",
      "24        5\n",
      "25        5\n",
      "26        6\n",
      "27        4\n",
      "28        4\n",
      "29        3\n",
      "         ..\n",
      "595182    4\n",
      "595183    5\n",
      "595184    3\n",
      "595185    4\n",
      "595186    4\n",
      "595187    5\n",
      "595188    4\n",
      "595189    4\n",
      "595190    3\n",
      "595191    5\n",
      "595192    6\n",
      "595193    4\n",
      "595194    3\n",
      "595195    5\n",
      "595196    6\n",
      "595197    4\n",
      "595198    3\n",
      "595199    4\n",
      "595200    3\n",
      "595201    6\n",
      "595202    5\n",
      "595203    2\n",
      "595204    4\n",
      "595205    4\n",
      "595206    4\n",
      "595207    6\n",
      "595208    6\n",
      "595209    3\n",
      "595210    5\n",
      "595211    3\n",
      "Name: bin_sum, Length: 595212, dtype: int64\n",
      "0         5\n",
      "1         5\n",
      "2         1\n",
      "3         4\n",
      "4         5\n",
      "5         5\n",
      "6         4\n",
      "7         3\n",
      "8         3\n",
      "9         4\n",
      "10        5\n",
      "11        4\n",
      "12        5\n",
      "13        3\n",
      "14        2\n",
      "15        4\n",
      "16        4\n",
      "17        6\n",
      "18        5\n",
      "19        3\n",
      "20        5\n",
      "21        4\n",
      "22        4\n",
      "23        5\n",
      "24        4\n",
      "25        5\n",
      "26        5\n",
      "27        4\n",
      "28        5\n",
      "29        5\n",
      "         ..\n",
      "892786    6\n",
      "892787    5\n",
      "892788    7\n",
      "892789    4\n",
      "892790    5\n",
      "892791    4\n",
      "892792    3\n",
      "892793    3\n",
      "892794    4\n",
      "892795    5\n",
      "892796    4\n",
      "892797    3\n",
      "892798    2\n",
      "892799    4\n",
      "892800    4\n",
      "892801    5\n",
      "892802    5\n",
      "892803    5\n",
      "892804    6\n",
      "892805    3\n",
      "892806    3\n",
      "892807    4\n",
      "892808    5\n",
      "892809    4\n",
      "892810    6\n",
      "892811    4\n",
      "892812    4\n",
      "892813    4\n",
      "892814    4\n",
      "892815    5\n",
      "Name: bin_sum, Length: 892816, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 실제 변수 이름을 알수 없어 피쳐 엔지니이렁시 초기에 방향성 찾기가 어려울 수 있음.\n",
    "# 3가지 기초 피쳐 엔지니어링 수행(파생변수 생성)\n",
    "# 2-2.  3가지 기초 피처 엔지니어링 수행 (파생 변수 생성)\n",
    "\n",
    "train_label = trn['target']\n",
    "train_id = trn['id']\n",
    "test_id = tst['id']\n",
    "del trn['target']\n",
    "del trn['id'] # id 와 target 삭제\n",
    "del tst['id'] # id삭제\n",
    "\n",
    "# 파생변수 01 : 결측값을 의미하는 '-1' 의 갯수를 센다.\n",
    "# 결측값의 합을 파생변수로 사용하는 이유는 해당 파생변수는 손쉽게 만들 수 있으며 효자 변수로 작용한 경우가 종종 있음.\n",
    "# 해당 대회 예시로는 결측값의 갯수가 데이터 내에 새로운 군집정보를 제공가능 \n",
    "# ex1) 초보 운전자들의 정보가 적을 수 있음 / ex2) 전국의 지부에서 모았을 때 특정 지점의 수집 오류 존재해서 결측값 처리 됬었을 수도 있음.\n",
    "trn['missing'] = (trn==-1).sum(axis=1).astype(float) # 가로축에 대한 missing 값을 세서 float형으로 나타냄\n",
    "tst['missing'] = (tst==-1).sum(axis=1).astype(float) # \n",
    "print(trn['missing'])\n",
    "print(tst['missing'])\n",
    "\n",
    "# 파생 변수 02 : 이진 변수의 합\n",
    "# 이진 변수는 값이 0 혹은 1이기 때문에 각 변수가 파생 변수에 미치는 영향력이 균등\n",
    "# 실수나 범주형 변수 간의 상호 작용 변수를 생성시 변수별 영향력 조절하는 작업 필요\n",
    "bin_features = [c for c in trn.columns if 'bin' in c]\n",
    "trn['bin_sum'] = trn[bin_features].sum(axis=1)\n",
    "tst['bin_sum'] = tst[bin_features].sum(axis=1)\n",
    "print(trn['bin_sum'])\n",
    "print(tst['bin_sum'])\n",
    "\n",
    "# 파생 변수 03 : 데이터 탐색 분석 과정에서 선별한 일부 변수를 대상으로 Target Encoding을 수행한다. Target Encoding은 교차 검증 과정에서 진행한다.\n",
    "# Target Encoding은 단일변수의 고유값별 타겟 변수의 평균값을 파생 변수로 활용하는 피쳐 엔지니어링 기법. 주로 범주형에서 좋은 성능을 보임.\n",
    "\n",
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', \n",
    "            'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM 모델 정의 완료\n",
      "Gini함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 2-3 LightGBM 모델의 설정 및 Gini 함수 정의.\n",
    "num_boost_round = 100 #10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 15,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.6,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9,\n",
    "          \"seed\": 2018\n",
    "}\n",
    "print('LightGBM 모델 정의 완료')\n",
    "\n",
    "# Gini 함수 정의\n",
    "import numpy as np\n",
    "\n",
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "cv_only = True\n",
    "save_cv = True\n",
    "full_train = False\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True\n",
    "\n",
    "print('Gini함수 정의 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_06_bin ok ,ps_ind_07_bin ok ,ps_ind_08_bin ok ,ps_ind_09_bin ok ,ps_ind_12_bin ok ,ps_ind_16_bin ok ,ps_ind_17_bin ok ,ps_ind_18_bin ok ,ps_ind_04_cat ok ,ps_ind_05_cat ok ,ps_car_01_cat ok ,ps_car_02_cat ok ,ps_car_03_cat ok ,ps_car_04_cat ok ,ps_car_06_cat ok ,ps_car_07_cat ok ,ps_car_08_cat ok ,ps_car_09_cat ok ,ps_car_11_cat ok ,ps_ind_01 ok ,ps_ind_03 ok ,ps_ind_15 ok ,ps_car_11 ok ,Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.152157\tvalid_0's gini: 0.272254\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.152146\tvalid_0's gini: 0.272423\n",
      "\n",
      " 0 번째 score: 0.27242252761962743  \n",
      "\n",
      "\n",
      "ps_ind_06_bin ok ,ps_ind_07_bin ok ,ps_ind_08_bin ok ,ps_ind_09_bin ok ,ps_ind_12_bin ok ,ps_ind_16_bin ok ,ps_ind_17_bin ok ,ps_ind_18_bin ok ,ps_ind_04_cat ok ,ps_ind_05_cat ok ,ps_car_01_cat ok ,ps_car_02_cat ok ,ps_car_03_cat ok ,ps_car_04_cat ok ,ps_car_06_cat ok ,ps_car_07_cat ok ,ps_car_08_cat ok ,ps_car_09_cat ok ,ps_car_11_cat ok ,ps_ind_01 ok ,ps_ind_03 ok ,ps_ind_15 ok ,ps_car_11 ok ,Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.152169\tvalid_0's gini: 0.272532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.152151\tvalid_0's gini: 0.273048\n",
      "\n",
      " 1 번째 score: 0.2730483343145785  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2-4. Stratified 5-Fold 내부 교차 검증을 준비\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgbm\n",
    "\n",
    "# 원래는 5 FOLD 인데 시간상 2FOLD 만 반복\n",
    "NFOLDS = 2 #5\n",
    "\n",
    "# 분리된 데이터 폴드내의 타겟 변수의 비율을 유지하기 위해 사이킷런의 StratifiedKFold 함수 사용.\n",
    "# 재현성을 위해 random_state는 고정\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218) \n",
    "kf = kfold.split(trn, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))    \n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "\n",
    "# 2-5.  5-FOLD이므로 5번 반복\n",
    "for i, (train_fold, validate) in enumerate(kf):\n",
    "    # 훈련/검증 데이터를 분리한다\n",
    "    X_train, X_validate, label_train, label_validate = trn.iloc[train_fold, :], trn.iloc[validate, :], train_label[train_fold], train_label[validate]\n",
    "    \n",
    "    # target encoding 피쳐 엔지니어링을 수행한다\n",
    "    for feature in features:\n",
    "        # 훈련 데이터에서 feature 고유값별 타겟 변수의 평균을 구한다\n",
    "        map_dic = pd.DataFrame([X_train[feature], label_train]).T.groupby(feature).agg('mean')\n",
    "        map_dic = map_dic.to_dict()['target']\n",
    "        # 훈련/검증/테스트 데이터에 평균값을 매핑한다\n",
    "        X_train[feature + '_target_enc'] = X_train[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        X_validate[feature + '_target_enc'] = X_validate[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        tst[feature + '_target_enc'] = tst[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        print(feature,'ok ', end=',')\n",
    "\n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    \n",
    "    # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾는다.\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100) # early_stopping_rounds=1000\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    \n",
    "    # 테스트 데이터에 대한 예측값을 cv_pred에 더한다.\n",
    "    cv_pred += bst.predict(tst, num_iteration=bst.best_iteration)\n",
    "    cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 점수를 출력한다.\n",
    "    score = Gini(label_validate, cv_train[validate])\n",
    "    print('\\n', i, '번째 score:', score,' \\n\\n')\n",
    "    fold_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GINI 계수 값 :  0.2726352774494828\n",
      "Fold 실행 점수 : [0.27242252761962743, 0.2730483343145785]\n",
      "[98, 88] 93.0\n"
     ]
    }
   ],
   "source": [
    "# 2-6. k번 학습한 모델의 예측값을 평균냄\n",
    "cv_pred /= NFOLDS # NFOLDS 갯수로 나눔 \n",
    "\n",
    "# 시드값별로 교차 검증 점수를 출력한다.\n",
    "print('  GINI 계수 값 : ', Gini(train_label, cv_train))\n",
    "print('Fold 실행 점수 :', fold_scores)\n",
    "print(best_trees, np.mean(best_trees))\n",
    "\n",
    "# 테스트 데이터에 대한 결과물을 저장한다.\n",
    "pd.DataFrame({'id': test_id, 'target': cv_pred}).to_csv('lgbm_baseline.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결론 요약\n",
    "- (1) 주최측에서 데이터 익명화와 전처리 과정을 꼼꼼하게 진행하여 별도로 데이터 정제 및 전처리를 수행 할 필요가없다\n",
    "- (2) 3가지 파생변수 생성시 결측값의 갯수를 나타내는 'missing변수' / 이진 변수들의 합을 나타내는 상호 작용 변수 / 데이터 탐색분석과정에서 얻은 예측력이 높은 일부 변수들을 대상으로 진행한 Target Encoding 파생변수 생성\n",
    "- (3) 2번의 Fold (원래는 5번)에서 학습한 모델의 예측값을 평균하여 테스트데이터에 대한 최종 예측값 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
