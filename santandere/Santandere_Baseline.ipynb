{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline\n",
    "- 총 2015-01-28 ~ 2016-06-28의 1년 6개월치 월별 고객 데이터가 제공된다.\n",
    "- 그중 2015-01-28 ~ 2016-05-28의 1년 5개월치 데이터는 훈련 데이터이고 나머지 1달은 테스트 데이터이다.\n",
    "- 대회의 목적 : 고객이 신규로 구매할 제품을 찾는 것.\n",
    "- 주어진 월별 데이터를 이용해 신규 구매를 예측하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13647309, 48) (929615, 24)\n",
      "데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "# 2-1 데이터 불러옴.\n",
    "trn = pd.read_csv('D:/dataset/santander-product-recommendation/train_ver2/train_ver2.csv')\n",
    "tst = pd.read_csv('D:/dataset/santander-product-recommendation/test_ver2/test_ver2.csv')\n",
    "print(trn.shape, tst.shape)\n",
    "\n",
    "#trn = trn[:1000000]\n",
    "#tst = tst[:90000]\n",
    "#print(trn.shape, tst.shape)\n",
    "\n",
    "print('데이터 로드 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 1단계 완료\n"
     ]
    }
   ],
   "source": [
    "## 2-2 데이터 전처리1 ##\n",
    "# 제품 변수이름을 별도로 저장해 놓는다.\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "# 제품 변수 결측값을 미리 0으로 대체한다.\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# 24개 제품 중 하나도 보유하지 않는 고객 데이터를 제거한다. / 보유한 경우 1\n",
    "no_product = trn[prods].sum(axis=1) == 0 # 세로축 합이 0인 경우를 찾음.\n",
    "trn = trn[~no_product]\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터를 통합한다. 테스트 데이터에 없는 제품 변수는 0으로 채운다.\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis=0)\n",
    "\n",
    "print('데이터 전처리 1단계 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
      "데이터 전처리 2단계 완료\n"
     ]
    }
   ],
   "source": [
    "## 2-2 데이터 전처리2\n",
    "# 학습에 사용할 변수를 담는 list이다.\n",
    "features = []\n",
    "\n",
    "# 범주형 변수를 .factorize() 함수를 통해 label encoding한다. 17개 범주형 중 12개만\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols: # 범주형 변수들\n",
    "    df[col], _info = df[col].factorize(na_sentinel=-99) # 범주값들을 숫자로 바꿈 결측값은 -99로 / _factorize() 두번쨰 리턴값은 범주값 index정보들\n",
    "    #print(df[col])\n",
    "    #print(_info)\n",
    "features += categorical_cols\n",
    "print(features)\n",
    "\n",
    "print('데이터 전처리 2단계 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento', 'age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente']\n",
      "데이터 전처리 3단계 완료\n"
     ]
    }
   ],
   "source": [
    "## 2-2 데이터 전처리3\n",
    "# 수치형 변수의 특이값과 결측값을 -99로 대체하고, 정수형으로 변환한다. (수치형변수 7개)\n",
    "# 정수형으로 변환하는 이유는 메모리를 작게 하기 위해서\n",
    "# age antiguedad, indrel_1mes 는 수치 변수가 object로 표현되어 있는 것.\n",
    "df['age'].replace(' NA', -99, inplace=True) # 변경한 df를 df로 사용하겠다.\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "# antiguedad : 은행거래누적기간\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "# renta : 가구총수입\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "# indrel_1mes : 월초기준 고객등급 (1: 1등급, 2:co-owner, P:potential, 3:former primary, 4:former-co-owner)\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True) # P가 잠재고객이라 5로\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "\n",
    "# 학습에 사용할 수치형 변수를 features에 추가한다.\n",
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']\n",
    "print(features)\n",
    "\n",
    "print('데이터 전처리 3단계 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento', 'age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente', 'fecha_alta_month', 'fecha_alta_year', 'ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
      "피쳐엔지니어링 1단계 완료\n"
     ]
    }
   ],
   "source": [
    "#  2-3 (피쳐 엔지니어링) 두 날짜 변수에서 연도와 월 정보를 추출한다.\n",
    "# 신규 구매 데이터가 계절성을 띄고 있으므로 단일 모델로 모든 데이터를 학습시킬지, 특정 월만 추출해서 학습을 진행할지 선택이 필요.\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0\n",
    "                                              if x.__class__ is float\n",
    "                                              else float(x.split('-')[1])\n",
    "                                              ).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0\n",
    "                                             if x.__class__ is float\n",
    "                                             else float(x.split('-')[0])\n",
    "                                             ).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0\n",
    "                                                      if x.__class__ is float\n",
    "                                                      else float(x.split('-')[1])\n",
    "                                                      ).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0\n",
    "                                                     if x.__class__ is float\n",
    "                                                     else float(x.split('-')[0])\n",
    "                                                     ).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
    "\n",
    "# 그 외 변수의 결측값은 모두 -99로 대체한다.\n",
    "df.fillna(-99, inplace=True)\n",
    "print(features)\n",
    "print('피쳐엔지니어링 1단계 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 (피쳐 엔지니어링) lag-1 데이터를 생성한다.\n",
    "- Baseline 모델에서는 24개의 고객 변수와, 4개의 날짜 변수 기반 파생변수, 24개의 lag-1변수를 사용함.\n",
    "- lag-1 변수는 N개월 전에 금융제품을 보유하고 잇었는지 여부를 나타내는 변수 lag-1은 1개월전에 가지고 있었음을 뜻함\n",
    "- 실제 성능을 높이기 위해선 lag-5 까지 즉 5개월 전까지 보유하고 있었는지 확인해 보는 것이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fecha_dato_prev', 'ncodpers', 'ind_empleado_prev',\n",
      "       'pais_residencia_prev', 'sexo_prev', 'age_prev', 'fecha_alta_prev',\n",
      "       'ind_nuevo_prev', 'antiguedad_prev', 'indrel_prev',\n",
      "       'ult_fec_cli_1t_prev', 'indrel_1mes_prev', 'tiprel_1mes_prev',\n",
      "       'indresi_prev', 'indext_prev', 'conyuemp_prev', 'canal_entrada_prev',\n",
      "       'indfall_prev', 'tipodom_prev', 'cod_prov_prev', 'nomprov_prev',\n",
      "       'ind_actividad_cliente_prev', 'renta_prev', 'segmento_prev',\n",
      "       'ind_ahor_fin_ult1_prev', 'ind_aval_fin_ult1_prev',\n",
      "       'ind_cco_fin_ult1_prev', 'ind_cder_fin_ult1_prev',\n",
      "       'ind_cno_fin_ult1_prev', 'ind_ctju_fin_ult1_prev',\n",
      "       'ind_ctma_fin_ult1_prev', 'ind_ctop_fin_ult1_prev',\n",
      "       'ind_ctpp_fin_ult1_prev', 'ind_deco_fin_ult1_prev',\n",
      "       'ind_deme_fin_ult1_prev', 'ind_dela_fin_ult1_prev',\n",
      "       'ind_ecue_fin_ult1_prev', 'ind_fond_fin_ult1_prev',\n",
      "       'ind_hip_fin_ult1_prev', 'ind_plan_fin_ult1_prev',\n",
      "       'ind_pres_fin_ult1_prev', 'ind_reca_fin_ult1_prev',\n",
      "       'ind_tjcr_fin_ult1_prev', 'ind_valo_fin_ult1_prev',\n",
      "       'ind_viv_fin_ult1_prev', 'ind_nomina_ult1_prev',\n",
      "       'ind_nom_pens_ult1_prev', 'ind_recibo_ult1_prev',\n",
      "       'fecha_alta_month_prev', 'fecha_alta_year_prev',\n",
      "       'ult_fec_cli_1t_month_prev', 'ult_fec_cli_1t_year_prev', 'int_date'],\n",
      "      dtype='object')\n",
      "lag-1 데이터 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 날짜를 숫자로 변환(기간 월 -> 수)하는 함수이다. \n",
    "# 2015-01-28은 1, 2016-06-28은 18로 변환된다\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")]\n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "# 날짜를 숫자로 변환하여 int_date에 저장한다\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. 변수명에 _prev를 추가한다.\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1\n",
    "print(df_lag.columns)\n",
    "print('lag-1 데이터 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento', 'age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente', 'fecha_alta_month', 'fecha_alta_year', 'ult_fec_cli_1t_month', 'ult_fec_cli_1t_year', 'ind_empleado_prev', 'pais_residencia_prev', 'sexo_prev', 'tiprel_1mes_prev', 'indresi_prev', 'indext_prev', 'conyuemp_prev', 'canal_entrada_prev', 'indfall_prev', 'tipodom_prev', 'nomprov_prev', 'segmento_prev', 'age_prev', 'antiguedad_prev', 'renta_prev', 'ind_nuevo_prev', 'indrel_prev', 'indrel_1mes_prev', 'ind_actividad_cliente_prev', 'fecha_alta_month_prev', 'fecha_alta_year_prev', 'ult_fec_cli_1t_month_prev', 'ult_fec_cli_1t_year_prev', 'ind_ahor_fin_ult1_prev', 'ind_aval_fin_ult1_prev', 'ind_cco_fin_ult1_prev', 'ind_cder_fin_ult1_prev', 'ind_cno_fin_ult1_prev', 'ind_ctju_fin_ult1_prev', 'ind_ctma_fin_ult1_prev', 'ind_ctop_fin_ult1_prev', 'ind_ctpp_fin_ult1_prev', 'ind_deco_fin_ult1_prev', 'ind_deme_fin_ult1_prev', 'ind_dela_fin_ult1_prev', 'ind_ecue_fin_ult1_prev', 'ind_fond_fin_ult1_prev', 'ind_hip_fin_ult1_prev', 'ind_plan_fin_ult1_prev', 'ind_pres_fin_ult1_prev', 'ind_reca_fin_ult1_prev', 'ind_tjcr_fin_ult1_prev', 'ind_valo_fin_ult1_prev', 'ind_viv_fin_ult1_prev', 'ind_nomina_ult1_prev', 'ind_nom_pens_ult1_prev', 'ind_recibo_ult1_prev']\n",
      "피쳐엔지니어링 2단계 완료\n"
     ]
    }
   ],
   "source": [
    "# 시간 오래걸리는 부분!\n",
    "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. \n",
    "# Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\n",
    "del df, df_lag\n",
    "\n",
    "# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)\n",
    "\n",
    "# lag-1 변수를 추가한다.\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]\n",
    "print(features)\n",
    "print('피쳐엔지니어링 2단계 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 1단계 - 학습,검정데이터 분리\n"
     ]
    }
   ],
   "source": [
    "## 2-5 모델 학습\n",
    "# 학습을 위하여 데이터를 훈련, 테스트용으로 분리한다.\n",
    "# 학습에는 2016-01-28 ~ 2016-04-28 데이터만 사용하고, 검증에는 2016-05-28 데이터를 사용한다.\n",
    "# colab환경 메모리 제약때문에 2016-01-28~2016-02-28 데이터만 사용하고, 검증에는 2016-03-28 데이터사용\n",
    "# test는 2016-04-28\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28']#, '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-04-28']\n",
    "del df_trn\n",
    "\n",
    "# 훈련 데이터에서 신규 구매 건수만 추출한다.\n",
    "X, Y = [], []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "# 훈련, 검증 데이터로 분리한다.\n",
    "vld_date = '2016-03-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]\n",
    "\n",
    "print('모델 학습 1단계 - 학습,검정데이터 분리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 2단계 - 파라미터셋팅\n"
     ]
    }
   ],
   "source": [
    "# 2-6 XGBoost 모델을 훈련 데이터에 학습\n",
    "# XGBoost 모델 parameter를 설정한다.\n",
    "# 파라미터 튜닝작업 . 단 파라미터 튜닝작업보다는 피처 엔지니어링에 더 많은 시간을 쏟을 것을 권장한다.\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 8, # 트리 모델의 최대 깊이 갑이 높을수록 더 복잡한 트리모델을 생성하며 과적합의 원인이 될수 있음.\n",
    "    'nthread': 4,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'eta': 0.1, # 딥러닝의 learning late와 같은 원리 값이 너무 높으면 학습잘안되고, 너무낮으면 학습이 느림\n",
    "    'min_child_weight': 10,\n",
    "    'colsample_bytree': 0.8, # 트리를 생성할 때 훈련 데이터에서 변수를 샘플링 해주는 비율 보통 0.6~0.9\n",
    "    'colsample_bylevel': 0.9, # 트리의 레벨 별로 훈련 데이터의 변수를 샘플링 해주는 비율 보통 0.6~0..9\n",
    "    'seed': 2018,\n",
    "    }\n",
    "print('모델 학습 2단계 - 파라미터셋팅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.72676\teval-mlogloss:2.73623\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.45917\teval-mlogloss:2.46999\n",
      "[2]\ttrain-mlogloss:2.27577\teval-mlogloss:2.28789\n",
      "[3]\ttrain-mlogloss:2.13594\teval-mlogloss:2.14914\n",
      "[4]\ttrain-mlogloss:2.02173\teval-mlogloss:2.03643\n",
      "[5]\ttrain-mlogloss:1.92538\teval-mlogloss:1.94125\n",
      "[6]\ttrain-mlogloss:1.84668\teval-mlogloss:1.86393\n",
      "[7]\ttrain-mlogloss:1.77834\teval-mlogloss:1.79636\n",
      "[8]\ttrain-mlogloss:1.71633\teval-mlogloss:1.73485\n",
      "[9]\ttrain-mlogloss:1.66322\teval-mlogloss:1.68277\n",
      "[10]\ttrain-mlogloss:1.61622\teval-mlogloss:1.63652\n",
      "[11]\ttrain-mlogloss:1.57250\teval-mlogloss:1.59384\n",
      "[12]\ttrain-mlogloss:1.53308\teval-mlogloss:1.55473\n",
      "[13]\ttrain-mlogloss:1.49890\teval-mlogloss:1.52150\n",
      "[14]\ttrain-mlogloss:1.46800\teval-mlogloss:1.49176\n",
      "[15]\ttrain-mlogloss:1.43821\teval-mlogloss:1.46289\n",
      "[16]\ttrain-mlogloss:1.41179\teval-mlogloss:1.43725\n",
      "[17]\ttrain-mlogloss:1.38808\teval-mlogloss:1.41483\n",
      "[18]\ttrain-mlogloss:1.36594\teval-mlogloss:1.39350\n",
      "[19]\ttrain-mlogloss:1.34565\teval-mlogloss:1.37423\n",
      "[20]\ttrain-mlogloss:1.32705\teval-mlogloss:1.35657\n",
      "[21]\ttrain-mlogloss:1.30918\teval-mlogloss:1.33923\n",
      "[22]\ttrain-mlogloss:1.29321\teval-mlogloss:1.32422\n",
      "[23]\ttrain-mlogloss:1.27844\teval-mlogloss:1.31032\n",
      "[24]\ttrain-mlogloss:1.26471\teval-mlogloss:1.29755\n",
      "[25]\ttrain-mlogloss:1.25150\teval-mlogloss:1.28506\n",
      "[26]\ttrain-mlogloss:1.23926\teval-mlogloss:1.27385\n",
      "[27]\ttrain-mlogloss:1.22789\teval-mlogloss:1.26328\n",
      "[28]\ttrain-mlogloss:1.21734\teval-mlogloss:1.25351\n",
      "[29]\ttrain-mlogloss:1.20781\teval-mlogloss:1.24499\n",
      "모델 학습 3단계 - 학습진행 및 모델저장\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 검증 데이터를 XGBoost 형태로 변환한다.\n",
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "# XGBoost 모델을 훈련 데이터로 학습한다!\n",
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "# num_boost_round=1000\n",
    "model = xgb.train(param, dtrn, num_boost_round=30, evals=watch_list, early_stopping_rounds=20)\n",
    "print('모델 학습 3단계 - 학습진행 및 모델저장')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP@7 계산공식\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # MAP@7 이므로, 최대 7개만 사용한다\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 점수를 부여하는 조건은 다음과 같다 :\n",
    "        # 예측값이 정답에 있고 (‘p in actual’)\n",
    "        # 예측값이 중복이 아니면 (‘p not in predicted[:i]’)\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 정답값이 공백일 경우, 무조건 0.0점을 반환한다\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 정답의 개수(len(actual))로 average precision을 구한다\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of list인 정답값(actual)과 예측값(predicted)에서 고객별 Average Precision을 구하고, np.mean()을 통해 평균을 계산한다\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapk_max: 0.04405787067087859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03734438470913438\n"
     ]
    }
   ],
   "source": [
    "# 2-7 학습한 모델을 저장 및 검증 데이터 MAP@7 계산\n",
    "import pickle\n",
    "pickle.dump(model, open(\"xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit\n",
    "\n",
    "# MAP@7 평가 척도를 위한 준비작업이다.\n",
    "# 고객 식별 번호를 추출한다.\n",
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
    "# 검증 데이터에서 신규 구매를 구한다.\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]\n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "\n",
    "# 고객별 신규 구매 정답 값을 add_vld_list에 저장하고, 총 count를 count_vld에 저장한다.\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1\n",
    "\n",
    "# 검증 데이터에서 얻을 수 있는 MAP@7 최고점을 미리 구한다. (0.042663)\n",
    "print('mapk_max:', mapk(add_vld_list, add_vld_list, 7, 0.0))\n",
    "\n",
    "# 검증 데이터에 대한 예측 값을 구한다.\n",
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
    "\n",
    "# 저번 달에 보유한 제품은 신규 구매가 불가하기 때문에, 확률값에서 미리 1을 빼준다\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# 검증 데이터 예측 상위 7개를 추출한다.\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y, p, ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y, p, ip in y_prods])\n",
    "\n",
    "# 검증 데이터에서의 MAP@7 점수를 구한다. (0.036466)\n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.72326\n",
      "[1]\ttrain-mlogloss:2.45436\n",
      "[2]\ttrain-mlogloss:2.27076\n",
      "[3]\ttrain-mlogloss:2.13106\n",
      "[4]\ttrain-mlogloss:2.01691\n",
      "[5]\ttrain-mlogloss:1.92039\n",
      "[6]\ttrain-mlogloss:1.84184\n",
      "[7]\ttrain-mlogloss:1.77345\n",
      "[8]\ttrain-mlogloss:1.71143\n",
      "[9]\ttrain-mlogloss:1.65845\n",
      "[10]\ttrain-mlogloss:1.61134\n",
      "[11]\ttrain-mlogloss:1.56784\n",
      "[12]\ttrain-mlogloss:1.52857\n",
      "[13]\ttrain-mlogloss:1.49448\n",
      "[14]\ttrain-mlogloss:1.46370\n",
      "[15]\ttrain-mlogloss:1.43411\n",
      "[16]\ttrain-mlogloss:1.40788\n",
      "[17]\ttrain-mlogloss:1.38437\n",
      "[18]\ttrain-mlogloss:1.36252\n",
      "[19]\ttrain-mlogloss:1.34244\n",
      "[20]\ttrain-mlogloss:1.32409\n",
      "[21]\ttrain-mlogloss:1.30624\n",
      "[22]\ttrain-mlogloss:1.29040\n",
      "[23]\ttrain-mlogloss:1.27580\n",
      "[24]\ttrain-mlogloss:1.26240\n",
      "[25]\ttrain-mlogloss:1.24930\n",
      "[26]\ttrain-mlogloss:1.23737\n",
      "[27]\ttrain-mlogloss:1.22623\n",
      "[28]\ttrain-mlogloss:1.21583\n",
      "[29]\ttrain-mlogloss:1.20647\n",
      "[30]\ttrain-mlogloss:1.19779\n",
      "[31]\ttrain-mlogloss:1.18902\n",
      "[32]\ttrain-mlogloss:1.18089\n",
      "[33]\ttrain-mlogloss:1.17342\n",
      "[34]\ttrain-mlogloss:1.16642\n",
      "[35]\ttrain-mlogloss:1.15963\n",
      "[36]\ttrain-mlogloss:1.15324\n",
      "[37]\ttrain-mlogloss:1.14719\n",
      "[38]\ttrain-mlogloss:1.14176\n",
      "[39]\ttrain-mlogloss:1.13649\n",
      "[40]\ttrain-mlogloss:1.13165\n",
      "[41]\ttrain-mlogloss:1.12699\n",
      "[42]\ttrain-mlogloss:1.12261\n",
      "Feature importance:\n",
      "('age', 4733)\n",
      "('antiguedad', 4025)\n",
      "('renta', 3635)\n",
      "('age_prev', 2740)\n",
      "('nomprov', 2656)\n",
      "('fecha_alta_month', 2431)\n",
      "('antiguedad_prev', 2300)\n",
      "('fecha_alta_year', 2211)\n",
      "('canal_entrada', 1531)\n",
      "('nomprov_prev', 1285)\n",
      "('ind_recibo_ult1_prev', 1146)\n",
      "('ind_cco_fin_ult1_prev', 1035)\n",
      "('renta_prev', 1012)\n",
      "('ind_ecue_fin_ult1_prev', 990)\n",
      "('canal_entrada_prev', 932)\n",
      "('sexo', 930)\n",
      "('ind_cno_fin_ult1_prev', 865)\n",
      "('ind_nom_pens_ult1_prev', 739)\n",
      "('fecha_alta_month_prev', 718)\n",
      "('ind_tjcr_fin_ult1_prev', 697)\n",
      "('fecha_alta_year_prev', 683)\n",
      "('segmento', 644)\n",
      "('tiprel_1mes', 621)\n",
      "('ind_reca_fin_ult1_prev', 592)\n",
      "('ind_actividad_cliente', 571)\n",
      "('ind_valo_fin_ult1_prev', 513)\n",
      "('segmento_prev', 506)\n",
      "('ind_nomina_ult1_prev', 491)\n",
      "('ind_dela_fin_ult1_prev', 457)\n",
      "('tiprel_1mes_prev', 406)\n",
      "('ind_ctma_fin_ult1_prev', 336)\n",
      "('ind_fond_fin_ult1_prev', 334)\n",
      "('ind_ctop_fin_ult1_prev', 304)\n",
      "('ind_actividad_cliente_prev', 300)\n",
      "('ind_nuevo', 288)\n",
      "('sexo_prev', 257)\n",
      "('ind_ctpp_fin_ult1_prev', 238)\n",
      "('indext', 215)\n",
      "('ind_plan_fin_ult1_prev', 168)\n",
      "('ind_nuevo_prev', 147)\n",
      "('ind_deco_fin_ult1_prev', 99)\n",
      "('indrel_1mes', 97)\n",
      "('ind_hip_fin_ult1_prev', 78)\n",
      "('indext_prev', 77)\n",
      "('ind_empleado_prev', 64)\n",
      "('ind_ctju_fin_ult1_prev', 33)\n",
      "('indrel_1mes_prev', 18)\n",
      "('pais_residencia_prev', 14)\n",
      "('ind_deme_fin_ult1_prev', 8)\n",
      "('ind_viv_fin_ult1_prev', 6)\n",
      "('pais_residencia', 6)\n",
      "('ind_empleado', 4)\n",
      "('indfall_prev', 4)\n",
      "('ind_pres_fin_ult1_prev', 1)\n",
      "('indfall', 1)\n",
      "('indrel', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Black\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# 2-8 테스트 데이터 예측 및 캐글 업로드\n",
    "\n",
    "# XGBoost 모델을 전체 훈련 데이터로 재학습한다!\n",
    "X_all = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]\n",
    "# 트리 개수를 늘어난 데이터 양만큼 비례해서 증가한다.\n",
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "\n",
    "# XGBoost 모델 재학습!\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
    "\n",
    "# 변수 중요도를 출력해본다. 예상하던 변수가 상위로 올라와 있는가?\n",
    "# XGBoost 모델이 자체지원하는 GET_FSCORE()를 통해 확인 가능.\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n",
    "\n",
    "# 캐글 제출을 위하여 테스트 데이터에 대한 예측 값을 구한다.\n",
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# 제출 파일을 생성한다.\n",
    "submit_file = open('xgb.baseline.2015-06-28', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
